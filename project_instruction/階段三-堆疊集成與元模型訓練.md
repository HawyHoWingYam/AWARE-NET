# 階段三：堆疊集成與元模型訓練

### 本階段是整個研究方案的 靈魂所在 。我們的目標是 構建一個比任何單一專家模型都更聰明的

**「決策大腦」（元模型）** 。我們將採用學術界和工業界公認的 **堆疊集成（Stacking）** 方法，智
能地融合前一階段訓練的兩個異構模型的知識，從而實現性能的躍升。

### 此階段的技術核心是 嚴格遵循防止數據洩漏的原則 ，為元模型創建一個乾淨、無偏的訓練集。

### 這需要精密的交叉驗證流程。

## 任務 3.1：生成元模型訓練集

**子目標** ：編寫一個自動化腳本 create_meta_dataset.py，它將執行一個K-Fold交叉驗證流
程，為我們完整的訓練集生成「無偏」的（Out-of-Fold）嵌入向量，這是訓練元模型的唯一合
規數據。

⚠ 重要提示：

本任務是整個項目中計算成本最高的環節，因其涉及多次重新訓練第二階段的重型模型。請確
保您有足夠的時間和計算資源。這個過程的嚴謹性是您研究結果可靠性的重要保證。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，現在我們需要為元模型準備其專屬的訓練數據。請為我編寫一個腳本
create_meta_dataset.py，用以實現一個嚴格的 **5-Fold堆疊（Stacking）數據生成流程** 。

**腳本功能需求：**

1. 初始化與數據劃分：

```
導入 pandas 讀取階段零生成的 train_manifest.csv。
使用 sklearn.model_selection.StratifiedKFold 將訓練集索引劃分為 5 個互不重疊的折
（Folds），確保每個折中真/偽樣本的比例與整體一致。
```
2. K-Fold 交叉訓練與預測循環：

```
創建一個主循環，迭代 5 次（對應 5 個折）。在每一次循環 k 中：
a. 數據準備：確定當前的訓練折（4/5的數據）和驗證折（1/5的數據）。
b. 重新訓練基礎模型：【此處為核心】調用階段二的訓練腳本（或其核心邏輯），在當前的
訓練折數據上，從頭開始分別訓練EfficientNetV2-B3和MaxViT模型。將模型保存在臨時路
徑中。
```

請在腳本中加入詳盡的日誌記錄和進度條（tqdm），以便於監控這個耗時較⻑的過程。並在
註釋中強調為何必須在每個折內重新訓練模型。”

## 任務 3.2：訓練元模型 (Meta-Model)

**子目標** ：使用 **任務3.1** 精心準備的數據集，訓練一個高性能、輕量級的LightGBM分類器。這
個元模型將學會如何根據兩個專家模型的深層特徵，做出比任何單一模型都更準確的最終判
決。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，請為我編寫一個腳本 train_meta_model.py，用於訓練我們的決策核心——元模
型。

**腳本功能需求：**

```
c. 提取嵌入向量：使用階段二，任務2.3的FeatureExtractor，加載剛剛在步驟 b 中訓練好
的模型，對當前的驗證折數據進行前向傳播，提取出嵌入向量。
d. 存儲結果：將當前驗證折的嵌入向量和對應的真實標籤追加保存到一個列表中。
```
3. 數據匯總與最終處理：

```
在 5 次循環全部結束後，您將擁有覆蓋了全部原始訓練集的「無偏」嵌入向量列表。
a. 拼接與保存：編寫一個函數，將EfficientNetV2-B3和MaxViT的嵌入向量進行拼接。
建議：在拼接前，可以先通過一個簡單的線性層（torch.nn.Linear）將它們投影到統一的
維度（例如 256 維），以進行歸一化和信息壓縮。
b. 最終輸出：將拼接後的最終特徵向量矩陣（X_meta）和對應的標籤向量（y_meta）保
存到磁盤，推薦使用 numpy 的 .npy 格式或 pandas 的 .parquet 格式。這就是我們元模型
的「御用」訓練集。
```
### 1. 數據加載：

```
編寫代碼以加載任務3.1生成的元模型訓練集（X_meta.npy 和 y_meta.npy）。
```
2. 元模型選擇：

```
我們選用 lightgbm.LGBMClassifier 作為元模型。請導入它。
```
3. 超參數調優：

```
在正式訓練前，使用sklearn.model_selection.GridSearchCV或RandomizedSearchCV進
行超參數搜索，以找到LightGBM的最佳配置。
待調優的參數：至少應包括 n_estimators, learning_rate, num_leaves, max_depth,
reg_alpha, reg_lambda。
```

### 請確保腳本的輸出清晰地展示了元模型的訓練過程和最終結果。”

### 當您完成本階段的任務後，您就構建了整個檢測系統中最智能、最核心的部分。您不再擁有幾

### 個獨立的模型，而是一個協同工作的、高度智能化的決策系統。接下來，我們就可以在 階段四

### 中，將所有部分組裝起來，並為移動端部署進行最後的衝刺。

```
數據劃分：在X_meta內部進行一次新的訓練/驗證劃分（例如90%/10%），專門用於超參
數搜索，以避免過擬合。
```
4. 模型訓練與保存：

```
使用找到的最佳超參數，在完整的元模型數據集 (X_meta, y_meta) 上訓練最終的
LGBMClassifier模型。
使用 joblib 或 pickle 將訓練好的元模型對象保存到文件中（例如 meta_model.pkl）。這個
文件就是我們集成系統的「大腦」。
```
5. 性能報告：

```
打印出超參數搜索過程中找到的最佳參數組合。
報告元模型在內部驗證集上的性能指標（AUC, F1-Score），以初步評估其性能。
```

