# 階段二：第二階段模型 - 精準分析器

## 📊 當前狀態：準備開始

### ✅ **前置條件已滿足**
- ✅ **階段一完成**: MobileNetV4 快速過濾器已實現並可訓練
- ✅ **數據管道**: 統一的256x256 PNG格式數據已準備
- ✅ **基礎設施**: PyTorch環境和GPU加速已配置

### 🎯 **階段二目標**
本階段的目標是鍛造我們級聯系統的「心臟」—— 兩個獨立且強大的精準分析模型。我們將分別訓練一個頂級的CNN模型 (EfficientNetV2-B3) 和一個創新的生成式-判別式混合模型 (GenConViT)，為第三階段的堆疊集成（Stacking）做好準備。這兩個模型的異構互補性是最終實現高精度的關鍵。

### 🔄 **開發狀態**: 待實現
階段二的實現將在階段一訓練完成並建立性能基準後開始。

以下是本階段每個任務的詳細引導Prompt。

## 任務 2.1：訓練 EfficientNetV2-B3 模型

**子目標** ：編寫一個獨立的訓練腳本 train_stage2_effnet.py，利用我們統一的數據集，訓
練一個高性能的 EfficientNetV2-B3 模型。這個模型將作為我們集成系統中的「局部特徵專
家」。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，現在我們開始訓練第二階段的第一個專家模型。請為我編寫一個訓練腳本
train_stage2_effnet.py。

**核心需求：**

請確保腳本能夠獨立運行，並在訓練結束後清晰地報告EfficientNetV2-B3的最佳性能指
標。”

1. **複用與調整** ：這個腳本的大部分結構可以複用 **階段一** 的 train_stage1.py。請以此為基
    礎進行修改。
2. **模型選擇** ：
    在 argparse 中，將 model_name 的默認值改為一個強大的EfficientNetV2版本，例
    如 efficientnetv2_b3.in21k_ft_in1k。這個模型在ImageNet-21k上預訓練過，並
    在1k上微調，具有非常強大的特徵提取能力。
3. **訓練配置** ：
    使用與階段一相同的數據集（train_manifest.csv, val_manifest.csv）和數據增
    強策略。
    你可以實驗稍大的批次大小（batch_size）或調整學習率（lr），因為
    EfficientNetV2的架構與MobileNetV4不同。
4. **輸出與保存** ：
    將模型的權重和日誌保存在一個新的目錄下，例如 output/stage2_effnet/。
    同樣地，根據 **驗證集的AUC分數** 保存最佳模型權重。


## 任務 2.2：訓練 GenConViT 模型

**子目標** ：訓練我們的第二個專家模型，一個創新的生成式-判別式混合架構，作為系統中的「生成式檢測專家」。GenConViT結合了ConvNeXt-Swin混合層和自編碼器組件，能夠通過重建任務檢測深度偽造中的生成式偽影。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，接下來我們訓練第二個、也是最具特色的專家模型。這個模型需要結合卷積的局部感
知能力和Transformer的全局建模能力。

**模型選型建議：**

**腳本編寫需求 (train_stage2_genconvit.py)：**

請在腳本註釋中簡要說明GenConViT的生成式-判別式混合架構優勢，並指出其在deepfake檢測中的獨特能力。"

## 任務 2.3：提取嵌入向量 (Embedding Vector)

**子目標** ：編寫一個通用的工具函數或腳本 feature_extractor.py，用於從我們訓練好的任
意模型中提取其在做出最終分類決策之前的深層特徵表示。這是 **階段三** 堆疊集成工作的數據基
礎。

```
GenConViT架構詳細說明：GenConViT是一個創新的生成式-判別式混合模型，具有以下核心優勢：
1. **ConvNeXt-Swin混合層**: 結合ConvNeXt的局部特徵提取和Swin Transformer的全局建模
2. **自編碼器組件**: 通過重建任務檢測生成式偽影和不一致性
3. **雙變體支持**: GenConViTED（編碼器-解碼器）和GenConViTVAE（變分自編碼器）
4. **預訓練模型**: 可從Hugging Face (Deressa/GenConViT) 獲取預訓練權重
5. **論文性能**: 在deepfake檢測中達到95.8%準確率，99.3% AUC
```
1. **創建新腳本** ：基於 train_stage2_effnet.py 創建一個新腳本
    train_stage2_genconvit.py。
2. **GenConViT集成** ：集成GenConViT源碼到 src/stage2/genconvit/ 目錄，
    或使用Hugging Face預訓練模型 (Deressa/GenConViT)。
3. **超參數調整** ：
    GenConViT需要特殊的損失函數組合：分類損失 + 重建損失 + KL散度損失（VAE變體）。
    建議使用論文推薦的學習率 1e-4，Adam優化器，以及保守的batch size（16）。
    實現溫度縮放和多階段訓練策略以獲得最佳性能。
4. **輸出與保存** ：
    將輸出目錄設置為 output/stage2_genconvit/。
    保存ED和VAE變體的最佳模型，並生成重建質量樣本。


✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，為了給第三階段的元模型準備訓練數據，請為我編寫一個工具腳本
feature_extractor.py。

**核心功能需求：**

### 這個腳本將是連接模型訓練和模型集成的關鍵橋樑，請確保其通用性和易用性。”

### 完成以上三個任務後，您將擁有兩個訓練精良、性能強大的異構專家模型，以及一個能夠從它

### 們之中提取深層知識的工具。至此，我們已經為構建最終的、更智能的集成系統鋪平了所有道

### 路，可以滿懷信心地邁向 階段三 。

1. **創建一個 FeatureExtractor 類** ：
    **初始化 (__init__)** ：接收模型名稱 (model_name) 和模型權重路徑
    (checkpoint_path) 作為參數。在內部，它會加載預訓練模型，並加載我們訓練好的
    權重。
    **修改模型結構** ：在初始化時，自動移除模型的最後一個分類層。
       **提示** ：對於timm庫中的模型，這通常可以通過將 num_classes 設置為 0 來實
       現：timm.create_model(model_name, pretrained=False,
          num_classes=0)。或者，手動將分類頭替換為一個恆等映射層：
          model.classifier = torch.nn.Identity()。
    **提取方法 (extract)** ：實現一個名為 extract 的方法，接收一個 DataLoader 作為
    輸入。
2. **extract 方法的詳細邏輯** ：
    將模型設置為評估模式 (self.model.eval())。
    遍歷DataLoader中的所有數據。
    執行前向傳播，得到每個批次的嵌入向量。
    將所有批次的嵌入向量和對應的真實標籤收集起來。
    方法最終返回兩個numpy數組：一個是包含所有嵌入向量的 embeddings 數組，另一
    個是包含所有標籤的 labels 數組。
3. **示例用法** ：
    在腳本的 if __name__ == "__main__": 部分，請提供一個清晰的示例，展示如何
    使用這個FeatureExtractor類來為我們的 **驗證集** 數據，分別提取EfficientNetV2-
       B3和GenConViT的特徵。


