# 階段二：第二階段模型 - 精準分析器

## 📊 當前狀態：準備開始

### ✅ **前置條件已滿足**
- ✅ **階段一完成**: MobileNetV4 快速過濾器已實現並可訓練
- ✅ **數據管道**: 統一的256x256 PNG格式數據已準備
- ✅ **基礎設施**: PyTorch環境和GPU加速已配置

### 🎯 **階段二目標**
本階段的目標是鍛造我們級聯系統的「心臟」—— 兩個獨立且強大的精準分析模型。我們將分別訓練一個頂級的CNN模型 (EfficientNetV2-B3) 和一個卷積-Transformer混合模型 (GenConViT 或其替代品)，為第三階段的堆疊集成（Stacking）做好準備。這兩個模型的互補性是最終實現高精度的關鍵。

### 🔄 **開發狀態**: 待實現
階段二的實現將在階段一訓練完成並建立性能基準後開始。

以下是本階段每個任務的詳細引導Prompt。

## 任務 2.1：訓練 EfficientNetV2-B3 模型

**子目標** ：編寫一個獨立的訓練腳本 train_stage2_effnet.py，利用我們統一的數據集，訓
練一個高性能的 EfficientNetV2-B3 模型。這個模型將作為我們集成系統中的「局部特徵專
家」。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，現在我們開始訓練第二階段的第一個專家模型。請為我編寫一個訓練腳本
train_stage2_effnet.py。

**核心需求：**

請確保腳本能夠獨立運行，並在訓練結束後清晰地報告EfficientNetV2-B3的最佳性能指
標。”

1. **複用與調整** ：這個腳本的大部分結構可以複用 **階段一** 的 train_stage1.py。請以此為基
    礎進行修改。
2. **模型選擇** ：
    在 argparse 中，將 model_name 的默認值改為一個強大的EfficientNetV2版本，例
    如 efficientnetv2_b3.in21k_ft_in1k。這個模型在ImageNet-21k上預訓練過，並
    在1k上微調，具有非常強大的特徵提取能力。
3. **訓練配置** ：
    使用與階段一相同的數據集（train_manifest.csv, val_manifest.csv）和數據增
    強策略。
    你可以實驗稍大的批次大小（batch_size）或調整學習率（lr），因為
    EfficientNetV2的架構與MobileNetV4不同。
4. **輸出與保存** ：
    將模型的權重和日誌保存在一個新的目錄下，例如 output/stage2_effnet/。
    同樣地，根據 **驗證集的AUC分數** 保存最佳模型權重。


## 任務 2.2：訓練 GenConViT (或其替代品) 模型

**子目標** ：訓練我們的第二個專家模型，一個卷積-Transformer混合體，作為系統中的「全局關
係專家」。由於GenConViT可能不是timm庫中的標準模型，我們將優先選擇一個性能卓越且
易於獲取的替代品。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，接下來我們訓練第二個、也是最具特色的專家模型。這個模型需要結合卷積的局部感
知能力和Transformer的全局建模能力。

**模型選型建議：**

**腳本編寫需求 (train_stage2_maxvit.py)：**

請在腳本註釋中簡要說明為何選擇MaxViT作為替代品，並指出其架構上的主要優勢。”

## 任務 2.3：提取嵌入向量 (Embedding Vector)

**子目標** ：編寫一個通用的工具函數或腳本 feature_extractor.py，用於從我們訓練好的任
意模型中提取其在做出最終分類決策之前的深層特徵表示。這是 **階段三** 堆疊集成工作的數據基
礎。

```
首選替代方案 ：我建議使用 MaxViT (Multi-Axis Vision Transformer) 作為 GenConViT
的強力替代品。MaxViT 在 timm 庫中有很好的支持，它巧妙地結合了局部卷積和全局稀
疏注意力，在效率和性能上都非常出色。請選擇一個大小適中的版本，例如
maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k。
備選方案 ：CoAtNet (Co-Scale Conv-Attentional Image Transformers) 也是一個非常優
秀的選擇。
```
1. **創建新腳本** ：基於 train_stage2_effnet.py 創建一個新腳本
    train_stage2_maxvit.py。
2. **修改模型名稱** ：在 argparse 中，將 model_name 的默認值改為你選擇的 MaxViT 或
    CoAtNet 模型。
3. **超參數調整** ：
    Transformer-based模型對學習率和優化器可能更敏感。建議可以嘗試稍低的初始學習
    率。
    有時為模型的不同部分（例如，卷積主幹和Transformer塊）設置不同的學習率（分層
    學習率）會帶來更好的效果，但作為初步嘗試，可以先使用統一的學習率。
4. **輸出與保存** ：
    將輸出目錄設置為 output/stage2_maxvit/。
    依然根據 **驗證集的AUC分數** 保存最佳模型。


✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，為了給第三階段的元模型準備訓練數據，請為我編寫一個工具腳本
feature_extractor.py。

**核心功能需求：**

### 這個腳本將是連接模型訓練和模型集成的關鍵橋樑，請確保其通用性和易用性。”

### 完成以上三個任務後，您將擁有兩個訓練精良、性能強大的異構專家模型，以及一個能夠從它

### 們之中提取深層知識的工具。至此，我們已經為構建最終的、更智能的集成系統鋪平了所有道

### 路，可以滿懷信心地邁向 階段三 。

1. **創建一個 FeatureExtractor 類** ：
    **初始化 (__init__)** ：接收模型名稱 (model_name) 和模型權重路徑
    (checkpoint_path) 作為參數。在內部，它會加載預訓練模型，並加載我們訓練好的
    權重。
    **修改模型結構** ：在初始化時，自動移除模型的最後一個分類層。
       **提示** ：對於timm庫中的模型，這通常可以通過將 num_classes 設置為 0 來實
       現：timm.create_model(model_name, pretrained=False,
          num_classes=0)。或者，手動將分類頭替換為一個恆等映射層：
          model.classifier = torch.nn.Identity()。
    **提取方法 (extract)** ：實現一個名為 extract 的方法，接收一個 DataLoader 作為
    輸入。
2. **extract 方法的詳細邏輯** ：
    將模型設置為評估模式 (self.model.eval())。
    遍歷DataLoader中的所有數據。
    執行前向傳播，得到每個批次的嵌入向量。
    將所有批次的嵌入向量和對應的真實標籤收集起來。
    方法最終返回兩個numpy數組：一個是包含所有嵌入向量的 embeddings 數組，另一
    個是包含所有標籤的 labels 數組。
3. **示例用法** ：
    在腳本的 if __name__ == "__main__": 部分，請提供一個清晰的示例，展示如何
    使用這個FeatureExtractor類來為我們的 **驗證集** 數據，分別提取EfficientNetV2-
       B3和MaxViT的特徵。


