# 階段零-項目基礎與環境建設

#### 本階段總目標 ：創建一個穩定、可複現的開發環境，並建立一個自動化的數據處理流程，將原

#### 始、混亂的數據集轉化為結構清晰、模型可直接使用的格式。這是整個項目最基礎但至關重要

#### 的一步。

## 任務 0.1：環境配置

**子目標** ：使用Conda創建一個隔離的Python環境，包含所有必需的庫，並確保版本兼容性，為
後續的開發和實驗掃清障礙。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，請為我的Deepfake檢測研究項目創建一個詳細的Conda環境配置文件
environment.yml。我的項目將基於PyTorch，並需要處理大量的圖像和影片數據，訓練多種
深度學習模型（包括CNN和Transformer），並使用梯度提升樹進行集成。

**具體需求如下：**

1. **文件名** ：environment.yml
2. **Python版本** ：請使用穩定且廣泛支持的 3.10。
3. **核心框架** ：
    pytorch：請指定版本 2.1 或更高。
    torchvision, torchaudio：需與PyTorch版本兼容。
    pytorch-cuda：請指定版本 11.8 或 12.1，以匹配目標GPU驅動。
4. **模型加載與處理** ：
    timm：用於方便地加載MobileNetV4, EfficientNetV2, GenConViT等預訓練模
型。
opencv-python：用於所有影片讀取、幀提取、圖像 resizing 等操作。
facenet-pytorch 或 mtcnn-pytorch：用於高效、準確的人臉檢測。請推薦一個並
加入配置。
5. **數據科學與評估** ：
    scikit-learn：用於計算AUC, F1-Score等指標及進行概率校準。
    lightgbm：用於訓練我們的元模型。
    pandas：用於創建和管理數據清單（manifest files）。
    numpy：基礎數值計算。
6. **可視化與輔助工具** ：
    matplotlib, seaborn：用於繪製結果圖表。
    tqdm：用於在處理數據和訓練時顯示進度條。


請在environment.yml文件中為每個庫添加簡短的註釋，說明其用途。最後，請提供通過此
文件創建Conda環境的命令行指令。”

### 任務 0.2：數據集準備與劃分

**子目標** ：編寫一個功能強大且可配置的Python腳本 (preprocess_datasets.py)，實現從下
載的原始數據集到結構化、已裁剪人臉圖像的自動化處理流程，並生成便於後續使用的數據清
單文件。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，請為我編寫一個詳細的Python數據預處理腳本 preprocess_datasets.py。這個腳本
是整個項目的數據基礎，必須做到魯棒、可配置且嚴格遵守數據劃分原則。

**腳本的核心功能需求如下：**

#### 腳本應將處理後的數據整理成以下結構：

```
jupyterlab：用於進行探索性數據分析和實驗。
```
#### 1. 目標目錄結構設計：

```
/data_root/
├── raw_datasets/ # 原始數據集存放處
│ ├── DFDC, FF++, Celeb-DF-v2, DF ...
├── processed_data/ # 處理後的人臉圖像存放處
│ ├── train/ # 統一的訓練集
│ │ ├── real/
│ │ └── fake/
│ ├── val/ # 統一的驗證集
│ │ ├── real/
│ │ └── fake/
│ └── final_test_sets/ # 【至關重要】完全隔離的最終測試集
│ ├── celebd_df_v2/
│ │ ├── real/
│ │ └── fake/
│ ├── ffpp/
│ │ ├── real/
│ │ └── fake/
│ └── deepfake_eval_2024/
│ └── ... (保持其原始結構或同樣分為real/fake)
└── manifests/ # 數據清單文件
├── train_manifest.csv
```

腳本開頭應包含一個配置區塊（例如一個Python dict或class），允許用戶輕鬆設置以下參數：

請實現一個核心函數，其輸入為單個影片的路徑及其標籤（real/fake），執行以下操作：

#### 4. 主執行流程：

**5. 生成數據清單 (Manifest Files)：**

```
├── val_manifest.csv
├── test_celebd_df_v2_manifest.csv
└── ...
```
#### 2. 腳本的可配置性：

#### RAW_DATA_PATH: 原始數據集根目錄。

#### PROCESSED_DATA_PATH: 處理後數據的輸出根目錄。

#### FACE_DETECTOR_SETTINGS: 人臉檢測器的參數（如置信度閾值）。

#### FRAME_INTERVAL: 每隔多少幀提取一次人臉（例如， 5 代表每 5 幀處理一次）。

```
IMAGE_SIZE: 保存人臉圖像的統一尺寸（例如， 224 x 224 ）。
BBOX_SCALE: 檢測到人臉邊界框後，向外擴展的比例（例如，1.3代表擴展30%，以包
含更多上下文信息）。
```
3. 核心處理邏輯（process_video函數）：

```
使用OpenCV逐幀讀取影片。
按設定的FRAME_INTERVAL間隔，對幀進行人臉檢測。
對於檢測到的每張人臉，根據BBOX_SCALE擴展邊界框。
將裁剪出的人臉圖像resize到IMAGE_SIZE。
根據影片的來源（訓練/驗證/測試）和標籤，將圖像保存到 第一點 定義的對應目錄結構
中。文件名應包含來源影片和幀號，以備追溯（如 video123_frame_0015.png）。
```
#### 腳本的主體部分應遍歷RAW_DATA_PATH下的各個數據集。

```
它需要能解析每個數據集 特有的元數據文件（metadata.json, label.csv等） ，以獲取每個
影片的真偽標籤和其官方的 訓練/驗證/測試集劃分 。
嚴格執行數據分離 ：
DF40, DFDC, Celeb-DF-v2, FF++ 的 訓練集和驗證集 部分，其處理後的人臉圖像
應分別放入 processed_data/train/ 和 processed_data/val/ 目錄下。
Celeb-DF-v2 和 FF++ 的 官方獨立測試集 ，其處理後的人臉圖像必須放入
processed_data/final_test_sets/ 下對應的子目錄中。
Deepfake-Eval-2024 數據集也同樣處理並放入 final_test_sets/。
```
```
在所有影片處理完成後，腳本應掃描processed_data目錄，為train, val以及
final_test_sets中的每一個子集，分別生成一個.csv格式的清單文件。
```

## 請確保最終產出的Python腳本有清晰的註釋，易於理解和

## 修改。”

#### 當您完成以上兩個任務後，您的項目就打下了堅實的基礎。接下來，我們就可以進入 階段一 ，

#### 開始訓練我們的第一個模型了。

```
每個清單文件至少包含兩列：filepath（指向已保存人臉圖像的相對路徑）和label
（ 0 代表real， 1 代表fake）。
```

