# 階段四：級聯系統整合與移動端優化

### 本階段的目標是 將所有獨立的組件「組裝」成一個完整、流暢的端到端檢測系統 ，並為其最終

### 在移動設備上的應用進行「瘦身」和「賦能」。這一步是從理論模型到實際應用的關鍵跳躍。

### 我們將首先整合推理邏輯，然後再進行複雜但回報豐厚的移動端優化。

## 任務 4.1：實現級聯推理邏輯

**子目標** ：編寫一個高級的Python類 CascadeDetector，它將作為我們整個檢測系統的統一接
口。這個類將封裝所有內部複雜的判斷邏輯，對外提供簡單的調用方式。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，現在請為我編寫一個名為 CascadeDetector 的Python類，並將其保存在
cascade_detector.py 文件中。這個類是我們整個檢測系統的集成核心。

**類的結構與功能需求如下：**

1. 初始化方法 ( **init** )：

```
該方法應接收所有必要模型和參數的路徑作為輸入。
在內部，它需要完成以下加載工作：
a. 加載階段一模型：加載任務1.1保存的MobileNetV4-Hybrid-Medium最佳權重，以及任務
1.2保存的溫度校準值T。
b. 加載階段二模型：加載階段二訓練好的EfficientNetV2-B3和MaxViT的最佳權重。
c. 加載階段三模型：使用joblib或pickle加載任務3.2訓練好的LightGBM元模型
(meta_model.pkl)。
d. 加載特徵投影層（可選但推薦）：如果任務3.1中使用了線性層來對齊嵌入向量，也需要
加載它們。
將所有加載的模型設置為評估模式 (.eval())。
```
2. 核心預測方法 (predict)：

```
該方法應接收一個單幀圖像 (a single frame) 作為輸入（例如一個PIL圖像或Numpy數
組）。
實現完整的級聯推理邏輯：
```
1. 預處理：對輸入幀進行必要的預處理（resize, normalize等）。


### 請確保這個類易於使用，並在註釋中清晰地標明每一步的邏輯。”

## 任務 4.2：精度優先的移動端優化

**子目標** ：為我們的神經網絡模型（MobileNetV4, EfficientNetV2, MaxViT）設計一個結合
了 **量化感知訓練 (QAT)** 和 **知識蒸餾 (KD)** 的高級優化流程。這一步的目標是在將模型大小壓縮
數倍的同時，盡可能地保留其原始精度。

✅ **詳細引導 Prompt (您可以直接複製使用):**

“你好，為了讓我們的模型能實際運行在移動設備上，請為我設計一個精度優先的優化流程，
並提供一個示例性的訓練腳本框架 optimize_for_mobile.py。

**核心優化策略：量化感知訓練 (QAT) + 知識蒸餾 (KD)**

**腳本框架與設計需求：**

2. 第一階段推理：將幀輸入MobileNetV4，獲取原始logit。
3. 概率校準：應用溫度縮放 prob_stage1 = sigmoid(logit / T)。
4. 級聯判斷：

```
應用我們設計的非對稱性保守閾值。例如：
if prob_stage1 > 0.98: 返回 ("real", prob_stage1)
elif prob_stage1 < 0.1: 返回 ("fake", prob_stage1)
else: 判定為「困難樣本」，進入下一階段。
```
5. 第二階段推理：

```
將「困難樣本」幀分別輸入EfficientNetV2-B3和MaxViT，提取其嵌入向量。
將兩個嵌入向量進行與訓練時相同的對齊與拼接，形成元模型的輸入特徵X_meta_input。
```
6. 元模型決策：

```
將X_meta_input輸入LightGBM元模型，使用.predict_proba()方法獲取最終的類別概率。
返回 ("fake", final_prob) 或 ("real", 1 - final_prob)。
```
3. 影片處理方法 (predict_video)：

```
（可選，作為便捷工具）實現一個predict_video方法，接收一個影片路徑，內部調用
predict方法處理每一幀（或按間隔採樣），並返回一個對整個影片的綜合判斷（例如，返
回偽造幀的比例或平均置信度）。
```
### 1. 定義教師與學生模型：


請為MobileNetV4、EfficientNetV2和MaxViT分別執行此優化流程。這個腳本將是連接學
術研究與工業部署的橋樑。”

```
教師模型 (Teacher)：我們在PC端訓練好的、全精度（FP32） 的EfficientNetV2-B3和
MaxViT模型。它們的知識將被用來「指導」學生。
學生模型 (Student)：我們將要部署的、INT8量化版的EfficientNetV2-B3和MaxViT模型。
框架集成：PyTorch提供了原生的QAT支持。請展示如何使用torch.quantization模塊來準
備學生模型（插入QuantStub和DeQuantStub）。
```
2. 設計組合損失函數 (Combined Loss Function)：

```
實現一個自定義的損失函數，它由兩部分構成：
a. 標準分類損失 (Hard Loss)：學生模型預測結果與真實標籤之間的
BCEWithLogitsLoss。
b. 蒸餾損失 (Soft Loss)：學生模型的輸出（logits）與教師模型輸出（logits）之間的損
失。推薦使用KL散度損失（KLDivLoss）。
計算方法：loss_kd = T^2 * KLDivLoss(log_softmax(student_logits/T),
softmax(teacher_logits/T))。這裡的T是蒸餾溫度，一個超參數，用於平滑教師的輸出，讓
學生學習到類間的更多信息。
總損失：total_loss = alpha hard_loss + (1 - alpha) soft_loss。alpha是平衡兩個損失權重
的超參數。
```
3. 實現QAT+KD訓練循環：

```
編寫一個訓練循環，加載我們的組合訓練集。
在每個訓練步驟中：
```
1. 獲取教師模型的輸出（logits），注意教師模型不參與梯度計算 (with torch.no_grad():)。
2. 獲取學生模型的輸出（logits）。
3. 使用上述的組合損失函數計算總損失。
4. 反向傳播，更新學生模型的權重。

```
這個過程相當於對學生模型進行微調，使其在適應量化操作的同時，努力模仿教師模型的
行為。
```
4. 模型轉換與保存：

```
在QAT訓練完成後，調用torch.quantization.convert將訓練好的QAT模型轉換為真正的
INT8量化模型。
保存這個輕量級、高性能的量化模型，以備後續轉換為TensorFlow Lite或ONNX格式進行
部署。
```

### 完成階段四後，您不僅擁有了一個邏輯上完整的檢測系統，還掌握了將其高效部署到資源受限

### 設備上的核心技術。您的項目已經從一個模型集合，蛻變為一個接近產品原型的解決方案。接

### 下來，就是用最嚴格的標準來檢驗它成色的 最後階段——綜合評估 。


