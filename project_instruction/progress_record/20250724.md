# Stage 2 Implementation Plan - Precision Analyzer (2025-07-24)

## 🎯 Stage 2 Overall Objective
Build the "heart" of the cascade system - two complementary precision analysis models that form heterogeneous expert analyzers for complex samples that cannot be determined by Stage 1.

## 📊 Current Project Status
- ✅ **Stage 0 Completed**: Environment setup, data preprocessing, multi-threading GPU acceleration
- ✅ **Stage 1 Completed**: MobileNetV4 fast filter with excellent performance (AUC: 0.9733, F1: 0.9706)
- ✅ **Documentation Updated**: All project documentation aligned with current implementation
- 🔄 **Stage 2 Starting**: Precision analyzer implementation begins

## 🚀 Stage 2 Core Architecture Strategy

### **Heterogeneous Complementarity Design**
The Stage 2 system employs two expert models with different architectural strengths:

1. **EfficientNetV2-B3 (CNN Expert)**:
   - **Specialization**: Local texture anomaly detection
   - **Strengths**: Frequency domain artifacts, edge inconsistencies, compression artifacts
   - **Role**: "Local Feature Expert" for detailed texture analysis

2. **GenConViT (Generative Hybrid Expert)**:
   - **Specialization**: Global semantic inconsistency + generative artifact detection
   - **Strengths**: ConvNeXt-Swin hybrid attention, autoencoder reconstruction, VAE latent analysis
   - **Role**: "Generative-Discriminative Expert" combining reconstruction and attention mechanisms

### **Integration Strategy**
- **Embedding Extraction**: Extract deep feature vectors before classification heads
- **Feature Alignment**: Project different dimensions to unified 256-D space
- **Stacking Preparation**: Prepare heterogeneous features for Stage 3 meta-model

## 📋 Stage 2 Implementation Tasks

### Task 2.1: EfficientNetV2-B3 Model Training ⏳
**Script**: `src/stage2/train_stage2_effnet.py`
**Timeline**: 3-4 hours
**Status**: 📋 Planned

**Technical Specifications**:
```python
# Model Configuration
model_name = "efficientnetv2_b3.in21k_ft_in1k"
input_size = (256, 256)
num_classes = 1

# Training Configuration
batch_size = 28  # Adjusted for EfficientNetV2 memory requirements
learning_rate = 5e-5  # Lower LR for larger model
weight_decay = 1e-4
epochs = 50
optimizer = "AdamW"
scheduler = "CosineAnnealingLR"

# Output Directory
output_dir = "output/stage2_effnet/"
```

**Implementation Points**:
- Base structure copied from `train_stage1.py`
- Model replacement: MobileNetV4 → EfficientNetV2-B3
- Memory optimization for larger model
- Same data augmentation strategy as Stage 1
- AUC-based model selection

**Expected Performance**:
- Target AUC: >0.90
- Target F1-Score: >0.85
- Training time: ~3-4 hours on GPU

### Task 2.2: GenConViT Dual-Mode Integration System ⏳
**Script**: `src/stage2/train_stage2_genconvit.py`
**Timeline**: 7-10 hours (双模式集成系统)
**Status**: 🔄 In Progress

**Technical Specifications**:
```python
# Model Configuration
model_variant = "GenConViTED"  # 或 GenConViTVAE
input_size = (256, 256)
num_classes = 1

# Training Configuration
batch_size = 16  # 更保守 (autoencoder + transformer)
learning_rate = 1e-4  # 论文推荐值
weight_decay = 1e-4
epochs = 50
optimizer = "Adam"  # GenConViT论文使用
scheduler = "StepLR"
step_size = 10
gamma = 0.1

# 损失权重配置
autoencoder_loss_weight = 0.1
classification_loss_weight = 0.9
vae_kl_loss_weight = 0.01  # 仅VAE变体

# Output Directory
output_dir = "output/stage2_genconvit/"
```

**Implementation Points**:
- 🔄 **Dual-Mode Integration**: Hybrid (custom) + Pre-trained (original) with seamless switching
- ✅ **GitHub Analysis Complete**: Full technical specification extracted from original repository
- 🔄 **Architecture Recreation**: ConvNeXt-Swin hybrid, ED/VAE variants, multi-loss training
- 🔄 **Pre-trained Integration**: Hugging Face weights + original code compatibility
- 📋 **Switching System**: Runtime mode selection with unified interface

**Expected Performance**:
- Target AUC: >0.93 (基于论文99.3% AUC)
- Target F1-Score: >0.88
- Training time: ~4-5 hours on GPU

### Task 2.3: Feature Extractor Implementation ⏳
**Script**: `src/stage2/feature_extractor.py`
**Timeline**: 2-3 hours (GenConViT复杂特征提取)
**Status**: 📋 Planned

**Core Functionality**:
```python
class FeatureExtractor:
    def __init__(self, model_name, checkpoint_path):
        # Load model with num_classes=0 (no classification head)
        # Load trained weights
        
    def extract(self, dataloader):
        # Extract embeddings from pre-classification layers
        # Return (embeddings, labels) as numpy arrays

class GenConViTFeatureExtractor:
    def __init__(self, model_path, variant="GenConViTED"):
        # 加载GenConViT模型
        # 移除最终分类头，保留特征提取部分
        
    def extract_features(self, dataloader):
        # 从ConvNeXt-Swin混合层提取特征
        # 从自编码器组件提取重建特征
        # 返回多层次特征组合
```

**Technical Requirements**:
- Support for both timm and GenConViT architectures
- Automatic classification head removal
- Multi-component feature extraction (ConvNeXt + Swin + AE features)
- Batch processing with GPU acceleration
- Memory-efficient embedding extraction

### Task 2.4: Utils and Evaluation Scripts ⏳
**Scripts**: `src/stage2/utils.py`, `src/stage2/evaluate_stage2.py`
**Timeline**: 1-2 hours
**Status**: 📋 Planned

**Utils Functions**:
- Checkpoint loading utilities for both timm and GenConViT models
- Evaluation metrics calculation
- Feature dimension alignment tools
- GenConViT-specific visualization helpers

**Evaluation Features**:
- Individual model performance assessment
- Cross-model complementarity analysis
- Embedding quality validation
- GenConViT reconstruction quality metrics
- Stage 3 preparation metrics

## 📁 Stage 2 Directory Structure (Updated)

```
src/stage2/
├── __init__.py
├── train_stage2_effnet.py        # EfficientNetV2-B3训练 ✅
├── train_stage2_genconvit.py     # GenConViT双模式训练 🔄
├── genconvit_manager.py          # 双模式管理器 (新) 🔄
├── genconvit/                    # GenConViT双模式集成 (新)
│   ├── __init__.py              # 统一接口
│   ├── hybrid/                  # 混合模式实现
│   │   ├── model.py            # 自定义GenConViT架构
│   │   ├── config.py           # 混合模式配置
│   │   └── utils.py            # 混合模式工具
│   ├── pretrained/             # 预训练模式集成
│   │   ├── original_model.py   # 原始模型包装器
│   │   ├── weight_loader.py    # 预训练权重管理
│   │   └── adapter.py          # AWARE-NET适配器
│   └── common/                 # 共享组件
│       ├── base.py            # 基础接口
│       └── losses.py          # 损失函数
├── feature_extractor.py          # 升级支持双模式GenConViT
├── utils.py                      # 通用工具函数
├── evaluate_stage2.py            # 阶段二评估
└── evaluate_genconvit_modes.py   # 模式比较工具 (新)

output/stage2/
├── effnet/                       # EfficientNetV2-B3输出
│   ├── best_model.pth
│   ├── training_log.csv
│   ├── training_curves.png
│   └── evaluation_results.json
└── genconvit/                    # GenConViT输出 (新)
    ├── best_model_ed.pth         # ED变体
    ├── best_model_vae.pth        # VAE变体 (可选)
    ├── training_log.csv
    ├── reconstruction_samples.png # 重建质量样本
    └── evaluation_results.json
```

## 🔧 Technical Implementation Strategy

### **Memory Management**
- **EfficientNetV2-B3**: Batch size 28 (balanced for ~12GB VRAM)
- **GenConViT**: Batch size 16 (conservative for autoencoder + attention)
- **Gradient Accumulation**: If needed for larger effective batch sizes

### **Learning Rate Strategy**
- **EfficientNetV2**: 5e-5 (proven for large CNN models)
- **GenConViT**: 1e-4 (论文推荐，Adam优化器)
- **GenConViT Scheduler**: StepLR with step_size=10, gamma=0.1

### **Data Pipeline Reuse**
- Same data augmentation as Stage 1
- Same manifest files (train_manifest.csv, val_manifest.csv)
- Consistent 256×256 input format
- Same normalization parameters

### **GenConViT Dual-Mode Integration Strategy**
```python
# 双模式管理器
from src.stage2.genconvit_manager import GenConViTManager

# 混合模式 (自定义实现)
manager = GenConViTManager(mode="hybrid")
model = manager.create_model(variant="ED")

# 预训练模式 (原始权重)
manager = GenConViTManager(mode="pretrained")
model = manager.load_pretrained("genconvit_ed_inference.pth")

# 自动模式 (智能选择)
manager = GenConViTManager(mode="auto")
model = manager.get_best_model()  # 根据可用性自动选择
```

## 🎯 Success Criteria

### **Performance Targets**
- **EfficientNetV2-B3 AUC**: >0.90
- **GenConViT AUC**: >0.93 (基于论文性能)
- **Individual Model F1**: >0.85 (EfficientNetV2), >0.88 (GenConViT)
- **Complementarity**: Different failure modes between CNN and generative methods
- **Feature Quality**: Rich embedding vectors for meta-learning

### **Integration Readiness**
- **Feature Extraction**: Clean embedding extraction from both architectures
- **Dimension Consistency**: Unified feature space (256-D after projection)
- **GenConViT Features**: Multi-modal features (reconstruction + attention + CNN)
- **Stage 3 Preparation**: Ready for K-Fold cross-validation pipeline

## 📈 Expected Timeline

| Task | Duration | Dependencies | Status |
|------|----------|--------------|--------|
| **Directory Setup** | 15 min | Stage 1 complete | 📋 Planned |
| **GenConViT Integration** | 2-3 hours | Directory setup | 📋 Planned |
| **Task 2.1: EfficientNetV2** | 3-4 hours | Directory setup | 📋 Planned |
| **Task 2.2: GenConViT** | 4-5 hours | GenConViT integrated | 📋 Planned |
| **Task 2.3: Feature Extractor** | 2-3 hours | Both models trained | 📋 Planned |
| **Task 2.4: Utils & Evaluation** | 1-2 hours | Feature extractor ready | 📋 Planned |
| **Integration Testing** | 1 hour | All tasks complete | 📋 Planned |

**Total Estimated Time**: 15-20 hours (双模式GenConViT集成系统复杂度)

## 🔗 Stage 3 Integration Preparation

### **Embedding Vector Strategy**
- **EfficientNetV2 Features**: CNN-based local texture features
- **GenConViT Features**: Multi-modal features
  - ConvNeXt-Swin attention features
  - Autoencoder reconstruction features  
  - VAE latent features (if using VAE variant)
- **Feature Fusion**: Concatenation after dimension alignment to 256-D
- **Meta-Learning Ready**: Prepared for LightGBM meta-model

### **Heterogeneous Architecture Comparison**
| 方面 | EfficientNetV2-B3 | GenConViT |
|------|------------------|-----------|
| **架构类型** | 纯CNN | 混合(CNN+Transformer+生成式) |
| **专长领域** | 局部纹理异常 | 全局语义+生成式伪影 |
| **特征类型** | 卷积特征 | 多模态特征(重建+注意力) |
| **计算复杂度** | 中等 | 较高 |
| **检测机制** | 判别式 | 生成式+判别式 |

### **K-Fold Readiness**
- **Model Retraining**: Both models ready for 5-fold cross-validation
- **Feature Extraction**: Automated embedding generation per fold
- **GenConViT Complexity**: Handle multi-component architecture in K-fold
- **Data Leakage Prevention**: Strict train/validation separation

## 📝 Current Action Items (Phase Implementation)

### ✅ **Completed**
1. **Create Stage 2 Directory Structure** ✅
2. **Implement EfficientNetV2-B3 Training Script** ✅ (AUC: 0.9775 in 1 epoch test)
3. **GenConViT Technical Analysis** ✅ (Complete GitHub + paper analysis)

### 🔄 **Phase 1: Foundation Architecture (In Progress)**
4. **Create Dual-Mode GenConViT Manager** 🔄
5. **Implement Hybrid GenConViT Recreation** 📋
6. **Setup Pre-trained Integration** 📋

### 📋 **Phase 2: Technical Implementation (Planned)**
7. **Model Architecture Implementation** 📋
8. **Configuration Management System** 📋
9. **Training Pipeline Integration** 📋

### 📋 **Phase 3: Integration & Testing (Planned)**
10. **AWARE-NET Framework Integration** 📋
11. **Switching Mechanism Implementation** 📋
12. **Testing & Validation** 📋

## 🎯 Stage 2 Success Definition (Updated)

Upon completion, Stage 2 will deliver:
- ✅ **EfficientNetV2-B3 Expert** (AUC >0.90) - COMPLETED with 0.9775 AUC
- 🔄 **GenConViT Dual-Mode System** with seamless switching capability
  - Hybrid mode: Custom recreation for perfect AWARE-NET integration  
  - Pretrained mode: Original 95.8% accuracy, 99.3% AUC performance
- ✅ **True Heterogeneous Complementarity** (CNN vs Generative-Discriminative)
- 🔄 **Multi-Modal Feature Extraction** (CNN + Transformer + Reconstruction + VAE)
- 📋 **Flexible Integration Strategy** with runtime mode switching
- 📋 **Ready for Stage 3** stacking ensemble with rich feature diversity
- 📋 **Comprehensive Evaluation** including mode comparison tools

This foundation will enable Stage 3 to build a meta-model that intelligently combines the strengths of both local texture analysis (EfficientNetV2) and global generative-discriminative analysis (GenConViT), achieving superior performance compared to any individual model.