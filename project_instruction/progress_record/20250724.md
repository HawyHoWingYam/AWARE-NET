# Stage 2 Implementation Plan - Precision Analyzer (2025-07-24)

## ðŸŽ¯ Stage 2 Overall Objective
Build the "heart" of the cascade system - two complementary precision analysis models that form heterogeneous expert analyzers for complex samples that cannot be determined by Stage 1.

## ðŸ“Š Current Project Status
- âœ… **Stage 0 Completed**: Environment setup, data preprocessing, multi-threading GPU acceleration
- âœ… **Stage 1 Completed**: MobileNetV4 fast filter with excellent performance (AUC: 0.9733, F1: 0.9706)
- âœ… **Documentation Updated**: All project documentation aligned with current implementation
- ðŸ”„ **Stage 2 Starting**: Precision analyzer implementation begins

## ðŸš€ Stage 2 Core Architecture Strategy

### **Heterogeneous Complementarity Design**
The Stage 2 system employs two expert models with different architectural strengths:

1. **EfficientNetV2-B3 (CNN Expert)**:
   - **Specialization**: Local texture anomaly detection
   - **Strengths**: Frequency domain artifacts, edge inconsistencies, compression artifacts
   - **Role**: "Local Feature Expert" for detailed texture analysis

2. **GenConViT (Generative Hybrid Expert)**:
   - **Specialization**: Global semantic inconsistency + generative artifact detection
   - **Strengths**: ConvNeXt-Swin hybrid attention, autoencoder reconstruction, VAE latent analysis
   - **Role**: "Generative-Discriminative Expert" combining reconstruction and attention mechanisms

### **Integration Strategy**
- **Embedding Extraction**: Extract deep feature vectors before classification heads
- **Feature Alignment**: Project different dimensions to unified 256-D space
- **Stacking Preparation**: Prepare heterogeneous features for Stage 3 meta-model

## ðŸ“‹ Stage 2 Implementation Tasks

### Task 2.1: EfficientNetV2-B3 Model Training â³
**Script**: `src/stage2/train_stage2_effnet.py`
**Timeline**: 3-4 hours
**Status**: ðŸ“‹ Planned

**Technical Specifications**:
```python
# Model Configuration
model_name = "efficientnetv2_b3.in21k_ft_in1k"
input_size = (256, 256)
num_classes = 1

# Training Configuration
batch_size = 28  # Adjusted for EfficientNetV2 memory requirements
learning_rate = 5e-5  # Lower LR for larger model
weight_decay = 1e-4
epochs = 50
optimizer = "AdamW"
scheduler = "CosineAnnealingLR"

# Output Directory
output_dir = "output/stage2_effnet/"
```

**Implementation Points**:
- Base structure copied from `train_stage1.py`
- Model replacement: MobileNetV4 â†’ EfficientNetV2-B3
- Memory optimization for larger model
- Same data augmentation strategy as Stage 1
- AUC-based model selection

**Expected Performance**:
- Target AUC: >0.90
- Target F1-Score: >0.85
- Training time: ~3-4 hours on GPU

### Task 2.2: GenConViT Dual-Mode Integration System â³
**Script**: `src/stage2/train_stage2_genconvit.py`
**Timeline**: 7-10 hours (åŒæ¨¡å¼é›†æˆç³»ç»Ÿ)
**Status**: ðŸ”„ In Progress

**Technical Specifications**:
```python
# Model Configuration
model_variant = "GenConViTED"  # æˆ– GenConViTVAE
input_size = (256, 256)
num_classes = 1

# Training Configuration
batch_size = 16  # æ›´ä¿å®ˆ (autoencoder + transformer)
learning_rate = 1e-4  # è®ºæ–‡æŽ¨èå€¼
weight_decay = 1e-4
epochs = 50
optimizer = "Adam"  # GenConViTè®ºæ–‡ä½¿ç”¨
scheduler = "StepLR"
step_size = 10
gamma = 0.1

# æŸå¤±æƒé‡é…ç½®
autoencoder_loss_weight = 0.1
classification_loss_weight = 0.9
vae_kl_loss_weight = 0.01  # ä»…VAEå˜ä½“

# Output Directory
output_dir = "output/stage2_genconvit/"
```

**Implementation Points**:
- ðŸ”„ **Dual-Mode Integration**: Hybrid (custom) + Pre-trained (original) with seamless switching
- âœ… **GitHub Analysis Complete**: Full technical specification extracted from original repository
- ðŸ”„ **Architecture Recreation**: ConvNeXt-Swin hybrid, ED/VAE variants, multi-loss training
- ðŸ”„ **Pre-trained Integration**: Hugging Face weights + original code compatibility
- ðŸ“‹ **Switching System**: Runtime mode selection with unified interface

**Expected Performance**:
- Target AUC: >0.93 (åŸºäºŽè®ºæ–‡99.3% AUC)
- Target F1-Score: >0.88
- Training time: ~4-5 hours on GPU

### Task 2.3: Feature Extractor Implementation â³
**Script**: `src/stage2/feature_extractor.py`
**Timeline**: 2-3 hours (GenConViTå¤æ‚ç‰¹å¾æå–)
**Status**: ðŸ“‹ Planned

**Core Functionality**:
```python
class FeatureExtractor:
    def __init__(self, model_name, checkpoint_path):
        # Load model with num_classes=0 (no classification head)
        # Load trained weights
        
    def extract(self, dataloader):
        # Extract embeddings from pre-classification layers
        # Return (embeddings, labels) as numpy arrays

class GenConViTFeatureExtractor:
    def __init__(self, model_path, variant="GenConViTED"):
        # åŠ è½½GenConViTæ¨¡åž‹
        # ç§»é™¤æœ€ç»ˆåˆ†ç±»å¤´ï¼Œä¿ç•™ç‰¹å¾æå–éƒ¨åˆ†
        
    def extract_features(self, dataloader):
        # ä»ŽConvNeXt-Swinæ··åˆå±‚æå–ç‰¹å¾
        # ä»Žè‡ªç¼–ç å™¨ç»„ä»¶æå–é‡å»ºç‰¹å¾
        # è¿”å›žå¤šå±‚æ¬¡ç‰¹å¾ç»„åˆ
```

**Technical Requirements**:
- Support for both timm and GenConViT architectures
- Automatic classification head removal
- Multi-component feature extraction (ConvNeXt + Swin + AE features)
- Batch processing with GPU acceleration
- Memory-efficient embedding extraction

### Task 2.4: Utils and Evaluation Scripts â³
**Scripts**: `src/stage2/utils.py`, `src/stage2/evaluate_stage2.py`
**Timeline**: 1-2 hours
**Status**: ðŸ“‹ Planned

**Utils Functions**:
- Checkpoint loading utilities for both timm and GenConViT models
- Evaluation metrics calculation
- Feature dimension alignment tools
- GenConViT-specific visualization helpers

**Evaluation Features**:
- Individual model performance assessment
- Cross-model complementarity analysis
- Embedding quality validation
- GenConViT reconstruction quality metrics
- Stage 3 preparation metrics

## ðŸ“ Stage 2 Directory Structure (Updated)

```
src/stage2/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ train_stage2_effnet.py        # EfficientNetV2-B3è®­ç»ƒ âœ…
â”œâ”€â”€ train_stage2_genconvit.py     # GenConViTåŒæ¨¡å¼è®­ç»ƒ ðŸ”„
â”œâ”€â”€ genconvit_manager.py          # åŒæ¨¡å¼ç®¡ç†å™¨ (æ–°) ðŸ”„
â”œâ”€â”€ genconvit/                    # GenConViTåŒæ¨¡å¼é›†æˆ (æ–°)
â”‚   â”œâ”€â”€ __init__.py              # ç»Ÿä¸€æŽ¥å£
â”‚   â”œâ”€â”€ hybrid/                  # æ··åˆæ¨¡å¼å®žçŽ°
â”‚   â”‚   â”œâ”€â”€ model.py            # è‡ªå®šä¹‰GenConViTæž¶æž„
â”‚   â”‚   â”œâ”€â”€ config.py           # æ··åˆæ¨¡å¼é…ç½®
â”‚   â”‚   â””â”€â”€ utils.py            # æ··åˆæ¨¡å¼å·¥å…·
â”‚   â”œâ”€â”€ pretrained/             # é¢„è®­ç»ƒæ¨¡å¼é›†æˆ
â”‚   â”‚   â”œâ”€â”€ original_model.py   # åŽŸå§‹æ¨¡åž‹åŒ…è£…å™¨
â”‚   â”‚   â”œâ”€â”€ weight_loader.py    # é¢„è®­ç»ƒæƒé‡ç®¡ç†
â”‚   â”‚   â””â”€â”€ adapter.py          # AWARE-NETé€‚é…å™¨
â”‚   â””â”€â”€ common/                 # å…±äº«ç»„ä»¶
â”‚       â”œâ”€â”€ base.py            # åŸºç¡€æŽ¥å£
â”‚       â””â”€â”€ losses.py          # æŸå¤±å‡½æ•°
â”œâ”€â”€ feature_extractor.py          # å‡çº§æ”¯æŒåŒæ¨¡å¼GenConViT
â”œâ”€â”€ utils.py                      # é€šç”¨å·¥å…·å‡½æ•°
â”œâ”€â”€ evaluate_stage2.py            # é˜¶æ®µäºŒè¯„ä¼°
â””â”€â”€ evaluate_genconvit_modes.py   # æ¨¡å¼æ¯”è¾ƒå·¥å…· (æ–°)

output/stage2/
â”œâ”€â”€ effnet/                       # EfficientNetV2-B3è¾“å‡º
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”œâ”€â”€ training_log.csv
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â””â”€â”€ evaluation_results.json
â””â”€â”€ genconvit/                    # GenConViTè¾“å‡º (æ–°)
    â”œâ”€â”€ best_model_ed.pth         # EDå˜ä½“
    â”œâ”€â”€ best_model_vae.pth        # VAEå˜ä½“ (å¯é€‰)
    â”œâ”€â”€ training_log.csv
    â”œâ”€â”€ reconstruction_samples.png # é‡å»ºè´¨é‡æ ·æœ¬
    â””â”€â”€ evaluation_results.json
```

## ðŸ”§ Technical Implementation Strategy

### **Memory Management**
- **EfficientNetV2-B3**: Batch size 28 (balanced for ~12GB VRAM)
- **GenConViT**: Batch size 16 (conservative for autoencoder + attention)
- **Gradient Accumulation**: If needed for larger effective batch sizes

### **Learning Rate Strategy**
- **EfficientNetV2**: 5e-5 (proven for large CNN models)
- **GenConViT**: 1e-4 (è®ºæ–‡æŽ¨èï¼ŒAdamä¼˜åŒ–å™¨)
- **GenConViT Scheduler**: StepLR with step_size=10, gamma=0.1

### **Data Pipeline Reuse**
- Same data augmentation as Stage 1
- Same manifest files (train_manifest.csv, val_manifest.csv)
- Consistent 256Ã—256 input format
- Same normalization parameters

### **GenConViT Dual-Mode Integration Strategy**
```python
# åŒæ¨¡å¼ç®¡ç†å™¨
from src.stage2.genconvit_manager import GenConViTManager

# æ··åˆæ¨¡å¼ (è‡ªå®šä¹‰å®žçŽ°)
manager = GenConViTManager(mode="hybrid")
model = manager.create_model(variant="ED")

# é¢„è®­ç»ƒæ¨¡å¼ (åŽŸå§‹æƒé‡)
manager = GenConViTManager(mode="pretrained")
model = manager.load_pretrained("genconvit_ed_inference.pth")

# è‡ªåŠ¨æ¨¡å¼ (æ™ºèƒ½é€‰æ‹©)
manager = GenConViTManager(mode="auto")
model = manager.get_best_model()  # æ ¹æ®å¯ç”¨æ€§è‡ªåŠ¨é€‰æ‹©
```

## ðŸŽ¯ Success Criteria

### **Performance Targets**
- **EfficientNetV2-B3 AUC**: >0.90
- **GenConViT AUC**: >0.93 (åŸºäºŽè®ºæ–‡æ€§èƒ½)
- **Individual Model F1**: >0.85 (EfficientNetV2), >0.88 (GenConViT)
- **Complementarity**: Different failure modes between CNN and generative methods
- **Feature Quality**: Rich embedding vectors for meta-learning

### **Integration Readiness**
- **Feature Extraction**: Clean embedding extraction from both architectures
- **Dimension Consistency**: Unified feature space (256-D after projection)
- **GenConViT Features**: Multi-modal features (reconstruction + attention + CNN)
- **Stage 3 Preparation**: Ready for K-Fold cross-validation pipeline

## ðŸ“ˆ Expected Timeline

| Task | Duration | Dependencies | Status |
|------|----------|--------------|--------|
| **Directory Setup** | 15 min | Stage 1 complete | ðŸ“‹ Planned |
| **GenConViT Integration** | 2-3 hours | Directory setup | ðŸ“‹ Planned |
| **Task 2.1: EfficientNetV2** | 3-4 hours | Directory setup | ðŸ“‹ Planned |
| **Task 2.2: GenConViT** | 4-5 hours | GenConViT integrated | ðŸ“‹ Planned |
| **Task 2.3: Feature Extractor** | 2-3 hours | Both models trained | ðŸ“‹ Planned |
| **Task 2.4: Utils & Evaluation** | 1-2 hours | Feature extractor ready | ðŸ“‹ Planned |
| **Integration Testing** | 1 hour | All tasks complete | ðŸ“‹ Planned |

**Total Estimated Time**: 15-20 hours (åŒæ¨¡å¼GenConViTé›†æˆç³»ç»Ÿå¤æ‚åº¦)

## ðŸ”— Stage 3 Integration Preparation

### **Embedding Vector Strategy**
- **EfficientNetV2 Features**: CNN-based local texture features
- **GenConViT Features**: Multi-modal features
  - ConvNeXt-Swin attention features
  - Autoencoder reconstruction features  
  - VAE latent features (if using VAE variant)
- **Feature Fusion**: Concatenation after dimension alignment to 256-D
- **Meta-Learning Ready**: Prepared for LightGBM meta-model

### **Heterogeneous Architecture Comparison**
| æ–¹é¢ | EfficientNetV2-B3 | GenConViT |
|------|------------------|-----------|
| **æž¶æž„ç±»åž‹** | çº¯CNN | æ··åˆ(CNN+Transformer+ç”Ÿæˆå¼) |
| **ä¸“é•¿é¢†åŸŸ** | å±€éƒ¨çº¹ç†å¼‚å¸¸ | å…¨å±€è¯­ä¹‰+ç”Ÿæˆå¼ä¼ªå½± |
| **ç‰¹å¾ç±»åž‹** | å·ç§¯ç‰¹å¾ | å¤šæ¨¡æ€ç‰¹å¾(é‡å»º+æ³¨æ„åŠ›) |
| **è®¡ç®—å¤æ‚åº¦** | ä¸­ç­‰ | è¾ƒé«˜ |
| **æ£€æµ‹æœºåˆ¶** | åˆ¤åˆ«å¼ | ç”Ÿæˆå¼+åˆ¤åˆ«å¼ |

### **K-Fold Readiness**
- **Model Retraining**: Both models ready for 5-fold cross-validation
- **Feature Extraction**: Automated embedding generation per fold
- **GenConViT Complexity**: Handle multi-component architecture in K-fold
- **Data Leakage Prevention**: Strict train/validation separation

## ðŸ“ Current Action Items (Phase Implementation)

### âœ… **Completed**
1. **Create Stage 2 Directory Structure** âœ…
2. **Implement EfficientNetV2-B3 Training Script** âœ… (AUC: 0.9775 in 1 epoch test)
3. **GenConViT Technical Analysis** âœ… (Complete GitHub + paper analysis)

### ðŸ”„ **Phase 1: Foundation Architecture (In Progress)**
4. **Create Dual-Mode GenConViT Manager** ðŸ”„
5. **Implement Hybrid GenConViT Recreation** ðŸ“‹
6. **Setup Pre-trained Integration** ðŸ“‹

### ðŸ“‹ **Phase 2: Technical Implementation (Planned)**
7. **Model Architecture Implementation** ðŸ“‹
8. **Configuration Management System** ðŸ“‹
9. **Training Pipeline Integration** ðŸ“‹

### ðŸ“‹ **Phase 3: Integration & Testing (Planned)**
10. **AWARE-NET Framework Integration** ðŸ“‹
11. **Switching Mechanism Implementation** ðŸ“‹
12. **Testing & Validation** ðŸ“‹

## ðŸŽ¯ Stage 2 Success Definition (Updated)

Upon completion, Stage 2 will deliver:
- âœ… **EfficientNetV2-B3 Expert** (AUC >0.90) - COMPLETED with 0.9775 AUC
- ðŸ”„ **GenConViT Dual-Mode System** with seamless switching capability
  - Hybrid mode: Custom recreation for perfect AWARE-NET integration  
  - Pretrained mode: Original 95.8% accuracy, 99.3% AUC performance
- âœ… **True Heterogeneous Complementarity** (CNN vs Generative-Discriminative)
- ðŸ”„ **Multi-Modal Feature Extraction** (CNN + Transformer + Reconstruction + VAE)
- ðŸ“‹ **Flexible Integration Strategy** with runtime mode switching
- ðŸ“‹ **Ready for Stage 3** stacking ensemble with rich feature diversity
- ðŸ“‹ **Comprehensive Evaluation** including mode comparison tools

This foundation will enable Stage 3 to build a meta-model that intelligently combines the strengths of both local texture analysis (EfficientNetV2) and global generative-discriminative analysis (GenConViT), achieving superior performance compared to any individual model.