# Stage 2 Implementation Plan - Precision Analyzer (2025-07-24)

## 🎯 Stage 2 Overall Objective
Build the "heart" of the cascade system - two complementary precision analysis models that form heterogeneous expert analyzers for complex samples that cannot be determined by Stage 1.

## 📊 Current Project Status
- ✅ **Stage 0 Completed**: Environment setup, data preprocessing, multi-threading GPU acceleration
- ✅ **Stage 1 Completed**: MobileNetV4 fast filter with excellent performance (AUC: 0.9733, F1: 0.9706)
- ✅ **Documentation Updated**: All project documentation aligned with current implementation
- 🔄 **Stage 2 Starting**: Precision analyzer implementation begins

## 🚀 Stage 2 Core Architecture Strategy

### **Heterogeneous Complementarity Design**
The Stage 2 system employs two expert models with different architectural strengths:

1. **EfficientNetV2-B3 (CNN Expert)**:
   - **Specialization**: Local texture anomaly detection
   - **Strengths**: Frequency domain artifacts, edge inconsistencies, compression artifacts
   - **Role**: "Local Feature Expert" for detailed texture analysis

2. **GenConViT (Generative Hybrid Expert)**:
   - **Specialization**: Global semantic inconsistency + generative artifact detection
   - **Strengths**: ConvNeXt-Swin hybrid attention, autoencoder reconstruction, VAE latent analysis
   - **Role**: "Generative-Discriminative Expert" combining reconstruction and attention mechanisms

### **Integration Strategy**
- **Embedding Extraction**: Extract deep feature vectors before classification heads
- **Feature Alignment**: Project different dimensions to unified 256-D space
- **Stacking Preparation**: Prepare heterogeneous features for Stage 3 meta-model

## 📋 Stage 2 Implementation Tasks

### Task 2.1: EfficientNetV2-B3 Model Training ⏳
**Script**: `src/stage2/train_stage2_effnet.py`
**Timeline**: 3-4 hours
**Status**: 📋 Planned

**Technical Specifications**:
```python
# Model Configuration
model_name = "efficientnetv2_b3.in21k_ft_in1k"
input_size = (256, 256)
num_classes = 1

# Training Configuration
batch_size = 28  # Adjusted for EfficientNetV2 memory requirements
learning_rate = 5e-5  # Lower LR for larger model
weight_decay = 1e-4
epochs = 50
optimizer = "AdamW"
scheduler = "CosineAnnealingLR"

# Output Directory
output_dir = "output/stage2_effnet/"
```

**Implementation Points**:
- Base structure copied from `train_stage1.py`
- Model replacement: MobileNetV4 → EfficientNetV2-B3
- Memory optimization for larger model
- Same data augmentation strategy as Stage 1
- AUC-based model selection

**Expected Performance**:
- Target AUC: >0.90
- Target F1-Score: >0.85
- Training time: ~3-4 hours on GPU

### Task 2.2: GenConViT Model Training ⏳
**Script**: `src/stage2/train_stage2_genconvit.py`
**Timeline**: 4-5 hours (更复杂的架构)
**Status**: 📋 Planned

**Technical Specifications**:
```python
# Model Configuration
model_variant = "GenConViTED"  # 或 GenConViTVAE
input_size = (256, 256)
num_classes = 1

# Training Configuration
batch_size = 16  # 更保守 (autoencoder + transformer)
learning_rate = 1e-4  # 论文推荐值
weight_decay = 1e-4
epochs = 50
optimizer = "Adam"  # GenConViT论文使用
scheduler = "StepLR"
step_size = 10
gamma = 0.1

# 损失权重配置
autoencoder_loss_weight = 0.1
classification_loss_weight = 0.9
vae_kl_loss_weight = 0.01  # 仅VAE变体

# Output Directory
output_dir = "output/stage2_genconvit/"
```

**Implementation Points**:
- GenConViT双网络架构 (ED/VAE变体)
- ConvNeXt-Swin混合层实现
- 自编码器重建损失 + 分类损失
- 预训练模型集成 (Hugging Face: Deressa/GenConViT)

**Expected Performance**:
- Target AUC: >0.93 (基于论文99.3% AUC)
- Target F1-Score: >0.88
- Training time: ~4-5 hours on GPU

### Task 2.3: Feature Extractor Implementation ⏳
**Script**: `src/stage2/feature_extractor.py`
**Timeline**: 2-3 hours (GenConViT复杂特征提取)
**Status**: 📋 Planned

**Core Functionality**:
```python
class FeatureExtractor:
    def __init__(self, model_name, checkpoint_path):
        # Load model with num_classes=0 (no classification head)
        # Load trained weights
        
    def extract(self, dataloader):
        # Extract embeddings from pre-classification layers
        # Return (embeddings, labels) as numpy arrays

class GenConViTFeatureExtractor:
    def __init__(self, model_path, variant="GenConViTED"):
        # 加载GenConViT模型
        # 移除最终分类头，保留特征提取部分
        
    def extract_features(self, dataloader):
        # 从ConvNeXt-Swin混合层提取特征
        # 从自编码器组件提取重建特征
        # 返回多层次特征组合
```

**Technical Requirements**:
- Support for both timm and GenConViT architectures
- Automatic classification head removal
- Multi-component feature extraction (ConvNeXt + Swin + AE features)
- Batch processing with GPU acceleration
- Memory-efficient embedding extraction

### Task 2.4: Utils and Evaluation Scripts ⏳
**Scripts**: `src/stage2/utils.py`, `src/stage2/evaluate_stage2.py`
**Timeline**: 1-2 hours
**Status**: 📋 Planned

**Utils Functions**:
- Checkpoint loading utilities for both timm and GenConViT models
- Evaluation metrics calculation
- Feature dimension alignment tools
- GenConViT-specific visualization helpers

**Evaluation Features**:
- Individual model performance assessment
- Cross-model complementarity analysis
- Embedding quality validation
- GenConViT reconstruction quality metrics
- Stage 3 preparation metrics

## 📁 Stage 2 Directory Structure

```
src/stage2/
├── __init__.py
├── train_stage2_effnet.py        # EfficientNetV2-B3训练
├── train_stage2_genconvit.py     # GenConViT训练
├── genconvit/                    # GenConViT源码集成 (新)
│   ├── __init__.py
│   ├── model.py                  # GenConViT模型定义
│   ├── config.py                 # 配置文件
│   └── utils.py                  # GenConViT工具函数
├── feature_extractor.py          # 升级支持GenConViT
├── utils.py                      # 通用工具函数
└── evaluate_stage2.py            # 阶段二评估

output/stage2/
├── effnet/                       # EfficientNetV2-B3输出
│   ├── best_model.pth
│   ├── training_log.csv
│   ├── training_curves.png
│   └── evaluation_results.json
└── genconvit/                    # GenConViT输出 (新)
    ├── best_model_ed.pth         # ED变体
    ├── best_model_vae.pth        # VAE变体 (可选)
    ├── training_log.csv
    ├── reconstruction_samples.png # 重建质量样本
    └── evaluation_results.json
```

## 🔧 Technical Implementation Strategy

### **Memory Management**
- **EfficientNetV2-B3**: Batch size 28 (balanced for ~12GB VRAM)
- **GenConViT**: Batch size 16 (conservative for autoencoder + attention)
- **Gradient Accumulation**: If needed for larger effective batch sizes

### **Learning Rate Strategy**
- **EfficientNetV2**: 5e-5 (proven for large CNN models)
- **GenConViT**: 1e-4 (论文推荐，Adam优化器)
- **GenConViT Scheduler**: StepLR with step_size=10, gamma=0.1

### **Data Pipeline Reuse**
- Same data augmentation as Stage 1
- Same manifest files (train_manifest.csv, val_manifest.csv)
- Consistent 256×256 input format
- Same normalization parameters

### **GenConViT Integration Strategy**
```python
# 预训练模型加载
from transformers import AutoModel
pretrained_model = AutoModel.from_pretrained("Deressa/GenConViT")

# 或者从GitHub源码集成
git clone https://github.com/erprogs/GenConViT
# 集成到 src/stage2/genconvit/
```

## 🎯 Success Criteria

### **Performance Targets**
- **EfficientNetV2-B3 AUC**: >0.90
- **GenConViT AUC**: >0.93 (基于论文性能)
- **Individual Model F1**: >0.85 (EfficientNetV2), >0.88 (GenConViT)
- **Complementarity**: Different failure modes between CNN and generative methods
- **Feature Quality**: Rich embedding vectors for meta-learning

### **Integration Readiness**
- **Feature Extraction**: Clean embedding extraction from both architectures
- **Dimension Consistency**: Unified feature space (256-D after projection)
- **GenConViT Features**: Multi-modal features (reconstruction + attention + CNN)
- **Stage 3 Preparation**: Ready for K-Fold cross-validation pipeline

## 📈 Expected Timeline

| Task | Duration | Dependencies | Status |
|------|----------|--------------|--------|
| **Directory Setup** | 15 min | Stage 1 complete | 📋 Planned |
| **GenConViT Integration** | 2-3 hours | Directory setup | 📋 Planned |
| **Task 2.1: EfficientNetV2** | 3-4 hours | Directory setup | 📋 Planned |
| **Task 2.2: GenConViT** | 4-5 hours | GenConViT integrated | 📋 Planned |
| **Task 2.3: Feature Extractor** | 2-3 hours | Both models trained | 📋 Planned |
| **Task 2.4: Utils & Evaluation** | 1-2 hours | Feature extractor ready | 📋 Planned |
| **Integration Testing** | 1 hour | All tasks complete | 📋 Planned |

**Total Estimated Time**: 13-18 hours (增加了GenConViT集成复杂度)

## 🔗 Stage 3 Integration Preparation

### **Embedding Vector Strategy**
- **EfficientNetV2 Features**: CNN-based local texture features
- **GenConViT Features**: Multi-modal features
  - ConvNeXt-Swin attention features
  - Autoencoder reconstruction features  
  - VAE latent features (if using VAE variant)
- **Feature Fusion**: Concatenation after dimension alignment to 256-D
- **Meta-Learning Ready**: Prepared for LightGBM meta-model

### **Heterogeneous Architecture Comparison**
| 方面 | EfficientNetV2-B3 | GenConViT |
|------|------------------|-----------|
| **架构类型** | 纯CNN | 混合(CNN+Transformer+生成式) |
| **专长领域** | 局部纹理异常 | 全局语义+生成式伪影 |
| **特征类型** | 卷积特征 | 多模态特征(重建+注意力) |
| **计算复杂度** | 中等 | 较高 |
| **检测机制** | 判别式 | 生成式+判别式 |

### **K-Fold Readiness**
- **Model Retraining**: Both models ready for 5-fold cross-validation
- **Feature Extraction**: Automated embedding generation per fold
- **GenConViT Complexity**: Handle multi-component architecture in K-fold
- **Data Leakage Prevention**: Strict train/validation separation

## 📝 Next Action Items

1. **Create Stage 2 Directory Structure**
2. **Integrate GenConViT Source Code**
3. **Implement EfficientNetV2-B3 Training Script**
4. **Implement GenConViT Training Script**
5. **Develop Enhanced Feature Extraction Framework**
6. **Build Evaluation and Utils for both architectures**
7. **Conduct Integration Testing**

## 🎯 Stage 2 Success Definition

Upon completion, Stage 2 will deliver:
- ✅ Two high-performance expert models (EfficientNetV2 AUC >0.90, GenConViT AUC >0.93)
- ✅ True heterogeneous complementarity (CNN vs Generative-Discriminative)
- ✅ Multi-modal feature extraction pipeline (CNN + Attention + Reconstruction)
- ✅ Ready for Stage 3 stacking ensemble with rich feature diversity
- ✅ Comprehensive evaluation and documentation

This foundation will enable Stage 3 to build a meta-model that intelligently combines the strengths of both local texture analysis (EfficientNetV2) and global generative-discriminative analysis (GenConViT), achieving superior performance compared to any individual model.